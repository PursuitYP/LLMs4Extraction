{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test OpenAI function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"What's the result of 22 plus 5 in decimal added to the hexadecimal number A?\"\n",
      "    }\n",
      "]\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"id\": \"chatcmpl-7UW4JF5YKVVZDqjbGO12O9Ct8LUH6\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1687507467,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"add_decimal_values\",\n",
      "          \"arguments\": \"{\\n  \\\"value1\\\": 22,\\n  \\\"value2\\\": 5\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 154,\n",
      "    \"completion_tokens\": 25,\n",
      "    \"total_tokens\": 179\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------\n",
      "22 + 5 = 27 (decimal)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"What's the result of 22 plus 5 in decimal added to the hexadecimal number A?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "            \"name\": \"add_decimal_values\",\n",
      "            \"arguments\": \"{\\n  \\\"value1\\\": 22,\\n  \\\"value2\\\": 5\\n}\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"function\",\n",
      "        \"name\": \"add_decimal_values\",\n",
      "        \"content\": \"{\\\"result\\\": 27 }\"\n",
      "    }\n",
      "]\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"id\": \"chatcmpl-7UW4KoLkD0qUT624iv9pPSHw3oE3m\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1687507468,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "          \"name\": \"add_hexadecimal_values\",\n",
      "          \"arguments\": \"{\\n  \\\"value1\\\": \\\"27\\\",\\n  \\\"value2\\\": \\\"A\\\"\\n}\"\n",
      "        }\n",
      "      },\n",
      "      \"finish_reason\": \"function_call\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 194,\n",
      "    \"completion_tokens\": 26,\n",
      "    \"total_tokens\": 220\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------\n",
      "27 + A = 31 (hex)\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[\n",
      "    {\n",
      "        \"role\": \"user\",\n",
      "        \"content\": \"What's the result of 22 plus 5 in decimal added to the hexadecimal number A?\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "            \"name\": \"add_decimal_values\",\n",
      "            \"arguments\": \"{\\n  \\\"value1\\\": 22,\\n  \\\"value2\\\": 5\\n}\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"function\",\n",
      "        \"name\": \"add_decimal_values\",\n",
      "        \"content\": \"{\\\"result\\\": 27 }\"\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": null,\n",
      "        \"function_call\": {\n",
      "            \"name\": \"add_hexadecimal_values\",\n",
      "            \"arguments\": \"{\\n  \\\"value1\\\": \\\"27\\\",\\n  \\\"value2\\\": \\\"A\\\"\\n}\"\n",
      "        }\n",
      "    },\n",
      "    {\n",
      "        \"role\": \"function\",\n",
      "        \"name\": \"add_hexadecimal_values\",\n",
      "        \"content\": \"{\\\"result\\\": 31 }\"\n",
      "    }\n",
      "]\n",
      "--------------------------------------------------\n",
      "{\n",
      "  \"id\": \"chatcmpl-7UW4Mp6zcfI7E14dhX0eTX0pGALMN\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1687507470,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"The result of adding 22 and 5 in decimal, and then adding the hexadecimal number A, is 31.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 236,\n",
      "    \"completion_tokens\": 25,\n",
      "    \"total_tokens\": 261\n",
      "  }\n",
      "}\n",
      "--------------------------------------------------\n",
      "The result of adding 22 and 5 in decimal, and then adding the hexadecimal number A, is 31.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "COMPLETION_MODEL = \"gpt-3.5-turbo-0613\"\n",
    "\n",
    "\n",
    "QUESTION = (\n",
    "    \"What's the result of 22 plus 5 in decimal added to the hexadecimal number A?\"\n",
    ")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": QUESTION},\n",
    "]\n",
    "\n",
    "\n",
    "def add_decimal_values(arguments):\n",
    "    value1 = int(re.search(r'\"value1\": (\\d+)', str(arguments)).group(1))\n",
    "    value2 = int(re.search(r'\"value2\": (\\d+)', str(arguments)).group(1))\n",
    "\n",
    "    result = value1 + value2\n",
    "    print(f\"{value1} + {value2} = {result} (decimal)\")\n",
    "\n",
    "    return value1 + value2\n",
    "\n",
    "\n",
    "def add_hexadecimal_values(arguments):\n",
    "    value1 = re.search(r'\"value1\": \"(\\w+)\"', str(arguments)).group(1)\n",
    "    value2 = re.search(r'\"value2\": \"(\\w+)\"', str(arguments)).group(1)\n",
    "\n",
    "    decimal1 = int(value1, 16)\n",
    "    decimal2 = int(value2, 16)\n",
    "\n",
    "    result = hex(decimal1 + decimal2)[2:]\n",
    "    print(f\"{value1} + {value2} = {result} (hex)\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_completion(messages):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=COMPLETION_MODEL,\n",
    "        messages=messages,\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"add_decimal_values\",\n",
    "                \"description\": \"Add two decimal values\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"value1\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The first decimal value to add. For example, 5\",\n",
    "                        },\n",
    "                        \"value2\": {\n",
    "                            \"type\": \"integer\",\n",
    "                            \"description\": \"The second decimal value to add. For example, 10\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"value1\", \"value2\"],\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"add_hexadecimal_values\",\n",
    "                \"description\": \"Add two hexadecimal values\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"value1\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The first hexadecimal value to add. For example, 5\",\n",
    "                        },\n",
    "                        \"value2\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"The second hexadecimal value to add. For example, A\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"value1\", \"value2\"],\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "while True:\n",
    "    print(json.dumps(messages, indent=4))\n",
    "    print(\"-\" * 50)\n",
    "    response = get_completion(messages)\n",
    "    print(response)\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    if response.choices[0][\"finish_reason\"] == \"stop\":\n",
    "        print(response.choices[0][\"message\"][\"content\"])\n",
    "        break\n",
    "\n",
    "    elif response.choices[0][\"finish_reason\"] == \"function_call\":\n",
    "        fn_name = response.choices[0].message[\"function_call\"].name\n",
    "        arguments = response.choices[0].message[\"function_call\"].arguments\n",
    "\n",
    "        function = locals()[fn_name]\n",
    "        result = function(arguments)\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": None,\n",
    "                \"function_call\": {\n",
    "                    \"name\": fn_name,\n",
    "                    \"arguments\": arguments,\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\", \n",
    "                \"name\": fn_name, \n",
    "                \"content\": f'{{\"result\": {str(result)} }}'}\n",
    "        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Pydantic + Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from openai_function_call import openai_function\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "@openai_function\n",
    "def sum(a:int, b:int) -> int:\n",
    "    \"\"\"Sum description adds a + b\"\"\"\n",
    "    return a + b\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        temperature=0,\n",
    "        functions=[sum.openai_schema],\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You must use the `sum` function instead of adding yourself.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is 6+3 use the `sum` function\",\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "\n",
    "result = sum.from_response(completion)\n",
    "print(result)  # 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='John Doe' age=30\n",
      "{'name': 'John Doe', 'age': 30}\n",
      "{\n",
      "    \"name\": \"John Doe\",\n",
      "    \"age\": 30\n",
      "}\n",
      "--------------------------------------------------\n",
      "{\n",
      "    \"title\": \"UserDetails\",\n",
      "    \"description\": \"User Details\",\n",
      "    \"type\": \"object\",\n",
      "    \"properties\": {\n",
      "        \"name\": {\n",
      "            \"description\": \"User's name\",\n",
      "            \"type\": \"string\"\n",
      "        },\n",
      "        \"age\": {\n",
      "            \"description\": \"User's age\",\n",
      "            \"type\": \"integer\"\n",
      "        }\n",
      "    },\n",
      "    \"required\": [\n",
      "        \"name\",\n",
      "        \"age\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from pydantic import Field, BaseModel\n",
    "from openai_function_call import OpenAISchema\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"http_proxy\"] = \"http://10.10.10.10:17890\"\n",
    "os.environ[\"https_proxy\"] = \"http://10.10.10.10:17890\"\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "class UserDetails(OpenAISchema):\n",
    "    \"\"\"User Details\"\"\"\n",
    "    name: str = Field(..., description=\"User's name\")\n",
    "    age: int = Field(..., description=\"User's age\")\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    functions=[UserDetails.openai_schema],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\", \n",
    "            \"content\": \"I'm going to ask for user details. Use UserDetails to parse this data.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\", \n",
    "            \"content\": \"My name is John Doe and I'm 30 years old.\"\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "\n",
    "user_details = UserDetails.from_response(completion)\n",
    "print(user_details)  # UserDetails(name=\"John Doe\", age=30)\n",
    "print(dict(user_details))\n",
    "print(json.dumps(dict(user_details), indent=4))\n",
    "print(\"-\" * 50)\n",
    "print(UserDetails.schema_json(indent=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Code_String Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "section_name: str = Field(..., description=\"section name\")\n",
      "location_of_the_samples_and_sections: str = Field(..., description=\"location of the samples and sections\")\n",
      "GPS_location: str = Field(..., description=\"GPS location\")\n",
      "associated_fossils: str = Field(..., description=\"associated fossils\")\n",
      "lithology: str = Field(..., description=\"lithology\")\n",
      "number_of_species_and_genera_found: str = Field(..., description=\"number of species and genera found\")\n",
      "----------------------------------------------------------------------------------------------------\n",
      "name: str = Field(..., description=\"User's name\")\n",
      "age: int = Field(..., description=\"User's age\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "field_list = [\"section name\", \"location of the samples and sections\", \"GPS location\", \n",
    "              \"associated fossils\", \"lithology\", \"number of species and genera found\"]\n",
    "attribute_set_string = \"\"\n",
    "for idx, field in enumerate(field_list):\n",
    "        new_attribute = f\"\"\"{field.replace(\" \", \"_\")}: str = Field(..., description=\"{field}\")\"\"\"\n",
    "        attribute_set_string = attribute_set_string + \"\\n\" + new_attribute\n",
    "print(attribute_set_string)\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# name: str = Field(..., description=\"User's name\")\n",
    "# age: int = Field(..., description=\"User's age\")\n",
    "\n",
    "attr1 = \"name\"\n",
    "attr2 = \"age\"\n",
    "code_string = f\"\"\"{attr1}: str = Field(..., description=\"User's name\")\n",
    "{attr2}: int = Field(..., description=\"User's age\")\n",
    "\"\"\"\n",
    "print(code_string)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Extraction w/o Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 16/16 [00:08<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"section name\": [\n",
      "        \"Abstract\",\n",
      "        \"Kunga Island section\"\n",
      "    ],\n",
      "    \"location of the samples and sections\": [\n",
      "        \"Kunga Island, Queen Charlotte Islands (QCI), and Inuyama\",\n",
      "        \"Queen Charlotte Islands, B.C. (Canada) and Inuyama\",\n",
      "        \"Queen Charlotte Islands, Canada\",\n",
      "        \"Queen Charlotte Islands, Canada; Inuyama, Japan\",\n",
      "        \"Queen Charlotte Islands, Canada; Inuyama, Kuzuu and Ikuno, Japan; New Zealand; Montenegro\"\n",
      "    ],\n",
      "    \"GPS location\": [],\n",
      "    \"associated fossils\": [],\n",
      "    \"lithology\": [],\n",
      "    \"number of species and genera found\": [\n",
      "        \"Nearly 20 genera and over 130 Rhaetian species disappeared at the end of the Triassic\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" LLMs for DeepShovel: 结构化数据抽取 \"\"\"\n",
    "import os\n",
    "import openai\n",
    "import textract\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from PyPDF2 import PdfReader\n",
    "import ast\n",
    "import json\n",
    "\n",
    "\n",
    "# Split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "def create_chunks(text, n, tokenizer):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    \"\"\"Yield successive n-sized chunks from text.\"\"\"\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "\n",
    "# 使用gpt-3.5-turbo抽取数据，加入异常处理机制\n",
    "def extract_chunk(document, template_prompt):\n",
    "    for i in range(3):  # Retry the API call up to 3 times\n",
    "        try:\n",
    "            prompt=template_prompt.replace('<document>', document)\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model='gpt-3.5-turbo', \n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=1500,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "            return \"1. \" + response['choices'][0]['message']['content']\n",
    "        except openai.error.RateLimitError:  # If rate limit is exceeded\n",
    "            wait_time = (2 ** i) + random.random()  # Exponential backoff with jitter\n",
    "            logging.warning(f\"Rate limit exceeded. Retrying after {wait_time} seconds.\")\n",
    "            time.sleep(wait_time)  # Wait before retrying\n",
    "        except Exception as e:  # If any other error occurs\n",
    "            logging.error(f\"API call failed: {str(e)}\")\n",
    "            return None  # Return None for failure\n",
    "    logging.error(\"Failed to call OpenAI API after multiple retries due to rate limiting.\")\n",
    "    return None  # Return None for failure\n",
    "\n",
    "\n",
    "# 调用API并使用重试机制处理rate limit error和其他异常\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    for i in range(3):  # Retry the API call up to 3 times\n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "            )\n",
    "            return response.choices[0].message[\"content\"]\n",
    "        except openai.error.RateLimitError:  # If rate limit is exceeded\n",
    "            wait_time = (2 ** i) + random.random()  # Exponential backoff with jitter\n",
    "            logging.warning(f\"Rate limit exceeded. Retrying after {wait_time} seconds.\")\n",
    "            time.sleep(wait_time)  # Wait before retrying\n",
    "        except Exception as e:  # If any other error occurs\n",
    "            logging.error(f\"API call failed: {str(e)}\")\n",
    "            return None  # Return None for failure\n",
    "    logging.error(\"Failed to call OpenAI API after multiple retries due to rate limiting.\")\n",
    "    return None  # Return None for failure\n",
    "\n",
    "\n",
    "# 处理过程信息写入log文件\n",
    "def log_to_file(log_file, message):\n",
    "    try:\n",
    "        with open(log_file, 'a') as file:\n",
    "            file.write(message + '\\n')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Failed to log to file {log_file}: {str(e)}')\n",
    "        raise\n",
    "\n",
    "\n",
    "# 使用PdfReader读取pdf文献，手动加入Page Number信息\n",
    "def read_pdf(filepath):\n",
    "    \"\"\"Takes a filepath to a PDF and returns a string of the PDF's contents\"\"\"\n",
    "    # creating a pdf reader object\n",
    "    reader = PdfReader(filepath)\n",
    "    pdf_text = \"\"\n",
    "    page_number = 0\n",
    "    for page in reader.pages:\n",
    "        page_number += 1\n",
    "        pdf_text += page.extract_text() + f\"\\nPage Number: {page_number}\"\n",
    "    return pdf_text\n",
    "\n",
    "\n",
    "# 传入pdf路径和带抽取的属性列表，返回抽取的结构化数据\n",
    "def data_extraction(pdf_path, field_list):\n",
    "    # 1. 执行pdf解析和切片\n",
    "    pdf_text = read_pdf(pdf_path)\n",
    "    clean_text = pdf_text.replace(\"  \", \" \").replace(\"\\n\", \"; \").replace(';',' ')\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    chunks = create_chunks(clean_text, 1000, tokenizer)\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "    # 2. 关键信息抽取：多线程对text_chunks处理，抽取关键信息\n",
    "    question_format = \"0. What is the value of the 'title' attribute\"\n",
    "    # 适应性地生成抽取问题，并集成到抽取提示extract_prompt中去\n",
    "    for idx, field in enumerate(field_list):\n",
    "        new_question = str(idx+1) + \". What is the value of the '\" + field + \"' attribute\"\n",
    "        question_format = question_format + \"\\n\" + new_question\n",
    "    document = '<document>'\n",
    "    # 关键信息抽取prompt\n",
    "    extract_prompt=f'''Extract key pieces of information from this regulation document.\n",
    "If a particular piece of information is not present, output \\\"Not specified\\\".\n",
    "When you extract a key piece of information, include the closest page number.\n",
    "---\n",
    "Use the following format:\n",
    "{question_format}\n",
    "---\n",
    "Document: \\\"\\\"\\\"{document}\\\"\\\"\\\"\\n\n",
    "0. What is the value of the 'title' attribute: Origin of Lower Carboniferous cherts in southern Guizhou, South China (Page 1)\n",
    "1.'''\n",
    "    # 多线程对text_chunks处理，抽取关键信息\n",
    "    results = []\n",
    "    log_file = 'log_geo_extract.txt'\n",
    "    # log_to_file(log_file, f'Number of chunks: {len(text_chunks)}')\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # 多线程处理\n",
    "        futures = {executor.submit(extract_chunk, chunk, extract_prompt): chunk for chunk in text_chunks}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc='Processing chunks'):\n",
    "            # 收集完成的线程处理好的结果\n",
    "            response = future.result()\n",
    "            if response is None:\n",
    "                # log_to_file(log_file, f'Failed to process chunk {futures[future]}')\n",
    "                pass\n",
    "            else:\n",
    "                # 汇总关键信息抽取的结果\n",
    "                results.append(response)\n",
    "                # log_to_file(log_file, f'Successfully processed chunk!')\n",
    "    # 进一步整理关键信息抽取结果，便于下一步格式化转换\n",
    "    groups = [r.split('\\n') for r in results]\n",
    "    groups = [y for x in groups for y in x]\n",
    "    groups = sorted(groups)\n",
    "    groups = [x for x in groups if \"Not specified\" not in x and \"__\" not in x]\n",
    "    zipped = groups\n",
    "    # 移除太长的结果 (保留len(r) <= 180)\n",
    "    zipped = [r for r in zipped if len(r) <= 180]\n",
    "\n",
    "    # 3. 数据格式转换：根据抽取的关键信息，转换生成JSON样式的结果\n",
    "    zipped_example = [\"1. What is the value of the 'section name' attribute: The end-Triassic extinction event (ETE) (Page 1)\", \"1. What is the value of the 'section name' attribute: Katsuyama section (Page 2)\", \"1. What is the value of the 'section name' attribute: The Inuyama area (Page 1)\", \"2. What is the value of the 'location of the samples and sections' attribute: Katsuyama section, Inuyama, Japan (Page 1)\", \"2. What is the value of the 'location of the samples and sections' attribute: Inuyama area, central Japan (Page 2)\", \"2. What is the value of the 'location of the samples and sections' attribute: Rock samples from TJ-3 to TJ + 4 (3 beds above TJ + 1) continuously (Page 2)\", \"3. What is the value of the 'GPS location' attribute: N 35◦25.367′, E 136◦58.261 (Page 2)\", \"4. What is the value of the 'associated fossils' attribute: Sea surface-dwelling radiolaria (Page 1)\", \"4. What is the value of the 'associated fossils' attribute: Radiolarian fossils (Page 1)\", \"4. What is the value of the 'associated fossils' attribute: Radiolarian fossils (Page 3)\", \"5. What is the value of the 'lithology' attribute: Bedded chert (Page 1)\", \"5. What is the value of the 'lithology' attribute: Bedded chert and siliciclastic rocks (Page 2)\", \"5. What is the value of the 'lithology' attribute: Siliceous mudstone, bedded chert sequence, and siliciclastic rocks (Page 1)\"]\n",
    "    zipped_str_example = str(zipped_example)[1:][:-1]\n",
    "    field_list_example = [\"section name\", \"location of the samples and sections\", \"GPS location\", \n",
    "                          \"associated fossils\", \"lithology\", \"number of species and genera found\"]\n",
    "    zipped_str = str(zipped)[1:][:-1]\n",
    "    # 数据格式转换prompt\n",
    "    transform_prompt = f'''You will read a paragraph, summarise it in JSON format according to keywords and remove duplicate values.\n",
    "---\n",
    "Here is an example: \n",
    "\n",
    "PARAGRAPH\n",
    "{zipped_str_example}\n",
    "KEYWORDS\n",
    "{field_list_example}\n",
    "OUTPUT\n",
    "{{\n",
    "    \"section name\": [\n",
    "        \"The end-Triassic extinction event (ETE)\",\n",
    "        \"Katsuyama section\",\n",
    "        \"The Inuyama area\"\n",
    "    ],\n",
    "    \"location of the samples and sections\": [\n",
    "        \"Katsuyama section, Inuyama, Japan\",\n",
    "        \"Inuyama area, central Japan\",\n",
    "        \"Rock samples from TJ-3 to TJ + 4 (3 beds above TJ + 1) continuously\"\n",
    "    ],\n",
    "    \"GPS location\": [\n",
    "        \"N 35◦25.367′, E 136◦58.261\"\n",
    "    ],\n",
    "    \"associated fossils\": [\n",
    "        \"Sea surface-dwelling radiolaria\",\n",
    "        \"Radiolarian fossils\"\n",
    "    ],\n",
    "    \"lithology\": [\n",
    "        \"Bedded chert\",\n",
    "        \"Bedded chert and siliciclastic rocks\",\n",
    "        \"Siliceous mudstone, bedded chert sequence, and siliciclastic rocks\"\n",
    "    ],\n",
    "    \"number of species and genera found\": []\n",
    "}}\n",
    "---\n",
    "Here is the paragragh you need to process, summarise it in JSON format according to keywords and remove duplicate values: \n",
    "\n",
    "PARAGRAPH\n",
    "{zipped_str}\n",
    "KEYWORDS\n",
    "{field_list}\n",
    "OUTPUT\n",
    "\n",
    "'''\n",
    "\n",
    "    response = get_completion(transform_prompt)\n",
    "    res_json = ast.literal_eval(response)\n",
    "\n",
    "    return res_json\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 环境初始化，用户上传OpenAI API key\n",
    "    load_dotenv()\n",
    "    os.environ[\"http_proxy\"] = \"http://10.10.1.3:10000\"\n",
    "    os.environ[\"https_proxy\"] = \"http://10.10.1.3:10000\"\n",
    "    # Load your API key from an environment variable or secret management service\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    os.environ['OPENAI_API_KEY'] = openai.api_key\n",
    "\n",
    "    # 用户上传pdf，输入需要抽取的属性列表\n",
    "    pdf_path = \"data/radiolarian/000.pdf\"\n",
    "    field_list = [\"section name\", \"location of the samples and sections\", \"GPS location\", \n",
    "                  \"associated fossils\", \"lithology\", \"number of species and genera found\"]\n",
    "    \n",
    "    # LLMs结构化数据抽取\n",
    "    res_json = data_extraction(pdf_path, field_list)\n",
    "    with open('results/result.json', 'w', newline='\\n') as file:\n",
    "        json.dump(res_json, file, indent=4)\n",
    "\n",
    "    print(json.dumps(res_json, indent=4))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Extraction w/ Function Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 12/12 [00:16<00:00,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"section_name\": \"5.3 Buryella tetradica -Bekoma campechensis interval zone (Page 7)\",\n",
      "    \"location_of_the_samples_and_sections\": \"Greater Indian passive continental margin (Page 21966)\",\n",
      "    \"GPS_location\": \"\",\n",
      "    \"associated_fossils\": \"Bekoma campechensis, Buryella tetradica, B. pentadica, Clathrocycloma (?) parcum, C. aff. catherinea (Page 7)\",\n",
      "    \"lithology\": \"burgundy and gray laminated siliceous shale and siliceous rocks (Page 5)\",\n",
      "    \"number_of_species_and_genera_found\": \"54 species of 30 radiolarian genera (Page 5)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" LLMs for DeepShovel: 结构化数据抽取 \"\"\"\n",
    "import os\n",
    "import openai\n",
    "import textract\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from PyPDF2 import PdfReader\n",
    "import ast\n",
    "import json\n",
    "from pydantic import Field, BaseModel\n",
    "from openai_function_call import OpenAISchema\n",
    "\n",
    "\n",
    "# Split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "def create_chunks(text, n, tokenizer):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    \"\"\"Yield successive n-sized chunks from text.\"\"\"\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "\n",
    "# 使用gpt-3.5-turbo抽取数据，加入异常处理机制\n",
    "def extract_chunk(document, template_prompt):\n",
    "    for i in range(3):  # Retry the API call up to 3 times\n",
    "        try:\n",
    "            prompt=template_prompt.replace('<document>', document)\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model='gpt-3.5-turbo', \n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ],\n",
    "                temperature=0,\n",
    "                max_tokens=1500,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "            return \"1. \" + response['choices'][0]['message']['content']\n",
    "        except openai.error.RateLimitError:  # If rate limit is exceeded\n",
    "            wait_time = (2 ** i) + random.random()  # Exponential backoff with jitter\n",
    "            logging.warning(f\"Rate limit exceeded. Retrying after {wait_time} seconds.\")\n",
    "            time.sleep(wait_time)  # Wait before retrying\n",
    "        except Exception as e:  # If any other error occurs\n",
    "            logging.error(f\"API call failed: {str(e)}\")\n",
    "            return None  # Return None for failure\n",
    "    logging.error(\"Failed to call OpenAI API after multiple retries due to rate limiting.\")\n",
    "    return None  # Return None for failure\n",
    "\n",
    "\n",
    "# 调用API并使用重试机制处理rate limit error和其他异常\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    for i in range(3):  # Retry the API call up to 3 times\n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "            )\n",
    "            return response.choices[0].message[\"content\"]\n",
    "        except openai.error.RateLimitError:  # If rate limit is exceeded\n",
    "            wait_time = (2 ** i) + random.random()  # Exponential backoff with jitter\n",
    "            logging.warning(f\"Rate limit exceeded. Retrying after {wait_time} seconds.\")\n",
    "            time.sleep(wait_time)  # Wait before retrying\n",
    "        except Exception as e:  # If any other error occurs\n",
    "            logging.error(f\"API call failed: {str(e)}\")\n",
    "            return None  # Return None for failure\n",
    "    logging.error(\"Failed to call OpenAI API after multiple retries due to rate limiting.\")\n",
    "    return None  # Return None for failure\n",
    "\n",
    "# 调用API并使用重试机制处理rate limit error和其他异常，调用function call功能\n",
    "def get_completion_function_call(prompt, attribute_set_string):\n",
    "    class AttributeDict(OpenAISchema):\n",
    "        \"\"\"Attributes of user input\"\"\"\n",
    "        exec(attribute_set_string)\n",
    "\n",
    "    for i in range(3):  # Retry the API call up to 3 times\n",
    "        try:\n",
    "            messages = [{\"role\": \"system\", \"content\": \"Use AttributeDict to parse this data.\"}, \n",
    "                        {\"role\": \"user\", \"content\": prompt}]\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                functions = [AttributeDict.openai_schema],\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "            )\n",
    "            return response\n",
    "        except openai.error.RateLimitError:  # If rate limit is exceeded\n",
    "            wait_time = (2 ** i) + random.random()  # Exponential backoff with jitter\n",
    "            logging.warning(f\"Rate limit exceeded. Retrying after {wait_time} seconds.\")\n",
    "            time.sleep(wait_time)  # Wait before retrying\n",
    "        except Exception as e:  # If any other error occurs\n",
    "            logging.error(f\"API call failed: {str(e)}\")\n",
    "            return None  # Return None for failure\n",
    "    logging.error(\"Failed to call OpenAI API after multiple retries due to rate limiting.\")\n",
    "    return None  # Return None for failure\n",
    "\n",
    "\n",
    "# 处理过程信息写入log文件\n",
    "def log_to_file(log_file, message):\n",
    "    try:\n",
    "        with open(log_file, 'a') as file:\n",
    "            file.write(message + '\\n')\n",
    "    except Exception as e:\n",
    "        logging.error(f'Failed to log to file {log_file}: {str(e)}')\n",
    "        raise\n",
    "\n",
    "\n",
    "# 使用PdfReader读取pdf文献，手动加入Page Number信息\n",
    "def read_pdf(filepath):\n",
    "    \"\"\"Takes a filepath to a PDF and returns a string of the PDF's contents\"\"\"\n",
    "    # creating a pdf reader object\n",
    "    reader = PdfReader(filepath)\n",
    "    pdf_text = \"\"\n",
    "    page_number = 0\n",
    "    for page in reader.pages:\n",
    "        page_number += 1\n",
    "        pdf_text += page.extract_text() + f\"\\nPage Number: {page_number}\"\n",
    "    return pdf_text\n",
    "\n",
    "\n",
    "# 传入pdf路径和带抽取的属性列表，返回抽取的结构化数据\n",
    "def data_extraction(pdf_path, field_list):\n",
    "    # 1. 执行pdf解析和切片\n",
    "    pdf_text = read_pdf(pdf_path)\n",
    "    clean_text = pdf_text.replace(\"  \", \" \").replace(\"\\n\", \"; \").replace(';',' ')\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    chunks = create_chunks(clean_text, 1000, tokenizer)\n",
    "    text_chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "    # 2. 关键信息抽取：多线程对text_chunks处理，抽取关键信息\n",
    "    question_format = \"0. What is the value of the 'title' attribute\"\n",
    "    # 适应性地生成抽取问题，并集成到抽取提示extract_prompt中去\n",
    "    for idx, field in enumerate(field_list):\n",
    "        new_question = str(idx+1) + \". What is the value of the '\" + field + \"' attribute\"\n",
    "        question_format = question_format + \"\\n\" + new_question\n",
    "    document = '<document>'\n",
    "    # 关键信息抽取prompt\n",
    "    extract_prompt=f'''Extract key pieces of information from this regulation document.\n",
    "If a particular piece of information is not present, output \\\"Not specified\\\".\n",
    "When you extract a key piece of information, include the closest page number.\n",
    "---\n",
    "Use the following format:\n",
    "{question_format}\n",
    "---\n",
    "Document: \\\"\\\"\\\"{document}\\\"\\\"\\\"\\n\n",
    "0. What is the value of the 'title' attribute: Origin of Lower Carboniferous cherts in southern Guizhou, South China (Page 1)\n",
    "1.'''\n",
    "    # 多线程对text_chunks处理，抽取关键信息\n",
    "    results = []\n",
    "    log_file = 'log_geo_extract.txt'\n",
    "    # log_to_file(log_file, f'Number of chunks: {len(text_chunks)}')\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        # 多线程处理\n",
    "        futures = {executor.submit(extract_chunk, chunk, extract_prompt): chunk for chunk in text_chunks}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc='Processing chunks'):\n",
    "            # 收集完成的线程处理好的结果\n",
    "            response = future.result()\n",
    "            if response is None:\n",
    "                # log_to_file(log_file, f'Failed to process chunk {futures[future]}')\n",
    "                pass\n",
    "            else:\n",
    "                # 汇总关键信息抽取的结果\n",
    "                results.append(response)\n",
    "                # log_to_file(log_file, f'Successfully processed chunk!')\n",
    "    # 进一步整理关键信息抽取结果，便于下一步格式化转换\n",
    "    groups = [r.split('\\n') for r in results]\n",
    "    groups = [y for x in groups for y in x]\n",
    "    groups = sorted(groups)\n",
    "    groups = [x for x in groups if \"Not specified\" not in x and \"__\" not in x]\n",
    "    zipped = groups\n",
    "    # 移除太长的结果 (保留len(r) <= 180)\n",
    "    zipped = [r for r in zipped if len(r) <= 180]\n",
    "\n",
    "    # 3. 数据格式转换：根据抽取的关键信息，转换生成JSON样式的结果\n",
    "    zipped_str = str(zipped)[1:][:-1]\n",
    "    # 数据格式转换prompt\n",
    "    transform_prompt = f'''I'm going to ask for attributes. Use AttributeDict to parse this data.\"\n",
    "---\n",
    "PARAGRAPH\n",
    "{zipped_str}\n",
    "'''\n",
    "\n",
    "    # 适应性地生成attribute_set_string, 在AttributeDict类中exec()生成可执行代码\n",
    "    attribute_set_string = \"\"\n",
    "    for idx, field in enumerate(field_list):\n",
    "        new_attribute = f\"\"\"{field.replace(\" \", \"_\")}: str = Field(..., description=\"{field}\")\"\"\"\n",
    "        attribute_set_string = attribute_set_string + \"\\n\" + new_attribute\n",
    "\n",
    "    class AttributeDict(OpenAISchema):\n",
    "        \"\"\"Attributes of user input\"\"\"\n",
    "        exec(attribute_set_string)\n",
    "\n",
    "    response = get_completion_function_call(transform_prompt, attribute_set_string)\n",
    "    arrtibutes = AttributeDict.from_response(response)\n",
    "    res_json = dict(arrtibutes)\n",
    "\n",
    "    return res_json\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 环境初始化，用户上传OpenAI API key\n",
    "    load_dotenv()\n",
    "    os.environ[\"http_proxy\"] = \"http://10.10.1.3:10000\"\n",
    "    os.environ[\"https_proxy\"] = \"http://10.10.1.3:10000\"\n",
    "    # os.environ[\"http_proxy\"] = \"http://10.10.10.10:17890\"\n",
    "    # os.environ[\"https_proxy\"] = \"http://10.10.10.10:17890\"\n",
    "    # Load your API key from an environment variable or secret management service\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    os.environ['OPENAI_API_KEY'] = openai.api_key\n",
    "\n",
    "    # 用户上传pdf，输入需要抽取的属性列表\n",
    "    pdf_path = \"data/radiolarian/466.pdf\"\n",
    "    field_list = [\"section name\", \"location of the samples and sections\", \"GPS location\", \n",
    "                  \"associated fossils\", \"lithology\", \"number of species and genera found\"]\n",
    "\n",
    "    # LLMs结构化数据抽取\n",
    "    res_json = data_extraction(pdf_path, field_list)\n",
    "    with open('results/result.json', 'w', newline='\\n') as file:\n",
    "        json.dump(res_json, file, indent=4)\n",
    "\n",
    "    print(json.dumps(res_json, indent=4))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test sentence similarity prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import random\n",
    "import logging\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "\n",
    "# 调用API并使用重试机制处理rate limit error和其他异常\n",
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    for i in range(3):  # Retry the API call up to 3 times\n",
    "        try:\n",
    "            messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0,\n",
    "            )\n",
    "            return response.choices[0].message[\"content\"]\n",
    "        except openai.error.RateLimitError:  # If rate limit is exceeded\n",
    "            wait_time = (2 ** i) + random.random()  # Exponential backoff with jitter\n",
    "            logging.warning(f\"Rate limit exceeded. Retrying after {wait_time} seconds.\")\n",
    "            time.sleep(wait_time)  # Wait before retrying\n",
    "        except Exception as e:  # If any other error occurs\n",
    "            logging.error(f\"API call failed: {str(e)}\")\n",
    "            return None  # Return None for failure\n",
    "    logging.error(\"Failed to call OpenAI API after multiple retries due to rate limiting.\")\n",
    "    return None  # Return None for failure\n",
    "\n",
    "\n",
    "sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "sentence2 = \"The quick yellow fox jumps over the lazy cat.\"\n",
    "prompt = f'''Please decide whether the following two sentences are semantically related.\n",
    "Your output can only be relevant or irrelevant.\n",
    "---\n",
    "SENTENCE 1: {sentence1}\n",
    "SENTENCE 2: {sentence2}\n",
    "OUTPUT\n",
    "'''\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "03cfac8420277217bc15eae6c08a9cabc6fb9173ce0ac6e9a0d7989c1c958163"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
